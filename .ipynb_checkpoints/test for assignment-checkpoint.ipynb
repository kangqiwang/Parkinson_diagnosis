{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-5.0202e-01 -5.6666e-01 -2.2567e-01  ...  -1.1091e+00 -6.4457e-01 -7.3276e-01\n",
      "-9.2222e-01 -1.0435e+00 -7.8610e-01  ...  -1.0050e+00 -6.4457e-01 -7.3276e-01\n",
      "-6.5019e-01 -7.1351e-01 -3.9780e-01  ...  -6.1540e-01 -5.2920e-03 -7.2061e-01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.0848e+00 -1.1180e+00 -9.6540e-01  ...  -1.1091e+00 -6.4457e-01 -7.3276e-01\n",
      "-1.0682e+00 -1.1071e+00 -9.4798e-01  ...  -1.1091e+00 -6.4457e-01 -7.3276e-01\n",
      "-1.0627e+00 -1.1071e+00 -9.6438e-01  ...  -1.1091e+00 -6.4457e-01 -7.3276e-01\n",
      "[torch.FloatTensor of size 1208x26]\n",
      " \n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "⋮ \n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 1208]\n",
      "\n",
      "Net(\n",
      "  (hidden): Linear(in_features=26, out_features=1000, bias=True)\n",
      "  (out): Linear(in_features=1000, out_features=2, bias=True)\n",
      ")\n",
      "Accuracy=0.58\n",
      "Accuracy=0.67\n",
      "Accuracy=0.72\n",
      "Accuracy=0.76\n",
      "Accuracy=0.79\n",
      "Accuracy=0.82\n",
      "Accuracy=0.85\n",
      "Accuracy=0.88\n",
      "Accuracy=0.79\n",
      "Accuracy=0.87\n",
      "Accuracy=0.88\n",
      "Accuracy=0.92\n",
      "Accuracy=0.95\n",
      "Accuracy=0.96\n",
      "Accuracy=0.97\n",
      "Accuracy=0.91\n",
      "Accuracy=0.82\n",
      "Accuracy=0.89\n",
      "Accuracy=0.94\n",
      "Accuracy=0.97\n",
      "Accuracy=0.98\n",
      "Accuracy=0.99\n",
      "Accuracy=0.99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-55b204a301ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\autograd\\variable.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[0;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \"\"\"\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m---> 99\u001b[1;33m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch\n",
    "N_HIDDEN=200\n",
    "\n",
    "test_data=np.loadtxt('test_data.txt',dtype='float',delimiter=',')\n",
    "train_data=np.loadtxt('train_data.txt',dtype='float64',delimiter=',')\n",
    "x_target=train_data[:,28]\n",
    "y_target=test_data[:,27]\n",
    "test_data=np.delete(test_data,27,1)\n",
    "train_data=np.delete(train_data,28,1)\n",
    "train_data=np.delete(train_data,27,1)\n",
    "train_data=np.delete(train_data,0,1)\n",
    "test_data=np.delete(test_data,0,1)\n",
    "\n",
    "x,y=np.concatenate((train_data,test_data),axis=0),np.concatenate((x_target,y_target),axis=0)\n",
    "x=scale(x)\n",
    "\n",
    "\n",
    "\n",
    "x,y=torch.from_numpy(x).type(torch.FloatTensor),torch.from_numpy(y).type(torch.LongTensor)\n",
    "\n",
    "x, y = Variable(x), Variable(y)\n",
    "\n",
    "print(x,'\\n')\n",
    "print(y)\n",
    "\n",
    "\n",
    "'''\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(26, N_HIDDEN),\n",
    "    torch.nn.Dropout(0.5),  # drop 50% of the neuron\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(N_HIDDEN, 1),\n",
    ")\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n",
    "    '''\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "        self.out = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "net = Net(26, 1000, 2)\n",
    "\n",
    "\n",
    "print(net)  # net architecture\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.02)\n",
    "loss_func = torch.nn.CrossEntropyLoss()  # the target label is NOT an one-hotted\n",
    "\n",
    "for t in range(500):\n",
    "    out = net(x)\n",
    "    #print(out)\n",
    "    loss=loss_func(out,y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if t % 50==0:\n",
    "        prediction = torch.max(out, 1)[1]\n",
    "        pred_y = prediction.data.numpy().squeeze()\n",
    "        target_y = y.data.numpy()\n",
    "        accuracy = float((pred_y == target_y).astype(int).sum()) / float(target_y.size)\n",
    "        print('Accuracy=%.2f' % accuracy)\n",
    "\n",
    "'''\n",
    "print('this is my x     ',x,'this is my y       ',y )\n",
    "\n",
    "print(test_data)\n",
    "print('this is my second data')\n",
    "print('this is my shape',test_data.shape)\n",
    "print('this is my shape',train_data.shape)\n",
    "print('this is my target x data     ',x_target.shape,'   this is my target y data',y_target.shape)\n",
    "print('\\n')\n",
    "print(train_data)\n",
    "print('\\n')\n",
    "\n",
    "y0 = torch.zeros(100)   \n",
    "print(y0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
